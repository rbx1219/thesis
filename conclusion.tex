\chapter{Conclusion} \label{ch:conclusion}

In this work, an algorithm with enhanced exploration for improving CMA-ES in a
rugged environment is proposed.
Different from traditional discretization approaches executing with
fixed settings to address the discretization, such as FHH and FWH, our
work defines a self-adaptive method to achieve a soft discretization.
The motivation is to tackle the difficulty that CMA-ES is easily to be
trapped in rugged problems as being an outstanding local optimizer.
We are first inspired from the method commonly applied in evolutionary
algorithms which keeps diversity by maintaining a larger population.
However, since the original design of CMA-ES is affected little by a
large population size, some modification on CMA-ES is required.
As a result, we integrate $k$-means clustering for dividing the
population into several groups.
With $k$ groups and the local optima from each, the important hypothesis
is that we believe the location where global optimum resides can be
retrieved from locations of local optima.
With the hypothesis, we further map our problem into a MAB problem which
investigates the trade-off between exploration and exploitation.
At last, we develop criteria to replace the arm which is believed to
contribute little to the overall system.

Consequently, the proposed MAB-based CMA-ES is an implementation which
combines CMA-ES, MAB problem and $k$-means clustering.
The results in the test problems showed that our algorithm is stabler
even in rugged fitness landscape comparing to rECGA, which is a
well-known improved discretization method addressed by SOD.
On the other hand, we can obtain high resolution results once the
position of the global optimum is roughly located.
The comparison of the two algorithms is given in the previous chapter.

In the aspect of exploration, both rECGA and MAB-based CMA-ES do not
dominate the other since they solved some functions, while the other one
is not able to reach the valley during the given number of function
evaluations.
Our algorithm won in 14 problems and lost in 4 considering the best
error values in the 25 runs of 25 problems, and won in 18 problems while
lost in 4 when it comes to the median.

In conclusion, the experiment results showed that our work performed
nicely in the trade-off between exploration and exploitation.
By maintaining a huge population and integrating a proper selection strategy,
we can further enhance the famous optimizer `CMA-ES' to gain more
diversity, which it originally lacks of. 
%An implicit information exists between the distributions so that we can
%obtain stabler results elegantly.

Although the design of our approach is still in early stage as the
deletion criteria, the number of generation for each pulling, etc.\ is
determined sketchily only, the result achieved in this work presents a
possible way for developing advanced exploration.
Also, the improvement from designing more robust strategies for
deletion criteria and tuning parameters can be expected.

